{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone proposal - Liberty Mutual Group Fire Peril Loss Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict expected fire losses for insurance policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main project idea and goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.kaggle.com/c/liberty-mutual-fire-peril\n",
    "\n",
    "This data set represents almost a million insurance records and the task is to predict a transformed ratio of loss to total insured value (called \"target\" within the data set). The provided features contain policy characteristics, information on crime rate, geodemographics, and weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What story you would like to tell with the data and what would you like to achieve at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My main goal is to show how important variables can be identified and how groups of variables can be compressed to a smaller representation. Furthermore, I'd like to show a possible approach to dealing with highly imbalanced data. Lastly, I'd like to show, if indeed the case, how an enseble of serveral models can be combined to one aggregate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) What is the main motivation behind your project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My main motivation is to work with a complex data set that is inherently imbalanced and contains many features. Also, in my job at the exchange, we are particularly interested in working with imbalanced data as anomaly and fraud detection are a major concern. However, since I cannot provide a data set from my employer for this capstone project and I also happen to be very interested in the particularities of the insurance industry, I chose the Liberty Mutual Fire Peril dataset as an interesting and alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What is the size and format of the data that you plan to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSV\n",
    "- Train: 902'789 rows and 302 columns\n",
    "- Test: 450'728 rows and 301 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) How do you expect to get, manage and process the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be downloaded as a zip file.\n",
    "I will download the zip file and load the csv's in a traditional manner in the the jupyter notebook (using `pd.read_csv()`).\n",
    "Since I will not be able to upload the zip file via github for submission, I will provide the kaggle link and download instructions in order for you to be able to run the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The analysis and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What are the main challenges that you envision for completing the project and how do you plan to get around each one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preliminary exploration indicates that the data is already in reasonable quality. Hence, the focus will be mainly on exploring the variables, feature engineering and building the models.\n",
    "- The main challenge with the data set is that it's very imbalanced, which makes predictions harder. Hence, the challenge will be to find out ways how to overcome the imbalance issue and what techniques can be used for that matter.\n",
    "- Also, the columns hardly provide any meaning, which will make feature engineering particularly difficult. The variables are named with a group prefix so that similarity among variables can be identified. Further details on the meaning of the variables, however, is not provided. Possibly, this is due to confidentiality reasons. One way around this problem could be the applications of feature compression techniques such as PCA or T-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What the are steps that you plan to take to achieve the end goals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Online research\n",
    "    - How to handle imbalanced data\n",
    "    - How to handle model predictions where the target variable is zero-inflated (many true negatives)\n",
    "    - I expect to have many small non-zero predictions as the coefficients will always have some sensitivity. However, how should I define cut-off values in order to determine when an observation is predicted to be zero?\n",
    "    - How to use PCA or, possibly, T-SNE for feature compression in regression problems.\n",
    "- Data exploration\n",
    "- Data cleansing \n",
    "- Data visualisation\n",
    "- Feature engineering\n",
    "- Defining prediction benchmark\n",
    "- Model selection and evaluation\n",
    "- Final predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Show us that you have a pipeline in place and that you understand the feasibility of your project goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data exploration\n",
    "The data exploration phase will focus on the distribution of data and evaluation of the quality of the data set. There, I will derive measures for the data cleansing step and get an idea which variables might be interesting and which not.\n",
    "\n",
    "####  2. Data cleansing (missing value imputation and removal of unnecessary rows and columns)\n",
    "Here, I might decide which rows or colums to drop from the dataset. Also, I will fill missing values with a specific rule. \n",
    "\n",
    "#### 3. Data visualisation (to show the relationship of the variables)\n",
    "In this chapter I intend to visualize the variables, its relations to each other and to the target variable.\n",
    "\n",
    "#### 4. Feature engineering\n",
    "\n",
    "Some first online research hinted the following steps that might be important when dealing with imbalanced data:\n",
    "\n",
    "    - determination of feature importance using methods provided in sklearn\n",
    "    - capping the target variable to make it less sensitive to outliers (censor large claims)\n",
    "    - downsampling of non-claims (true negatives) to reduce data set imbalance\n",
    "    - noise reduction through feature selection\n",
    "    - PCA and, possibly, T-SNE for feature compression\n",
    "    \n",
    "#### 5. Defining prediction benchmark\n",
    "The intention is to define a simple benchmark, such as linear regression.\n",
    "\n",
    "#### 6. Model selection and evaluation\n",
    "Models that could be used:\n",
    "\n",
    "    - K-Nearest Neighbors Regression\n",
    "    - Support Vector Regression\n",
    "    - Random Forest Regression\n",
    "    - Neural Network\n",
    "    - Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "During the course of building and evaluating the model, and if time allows, I would also like to experiment with combinations and aggregations of multiple models in order to improve performance.\n",
    "\n",
    "#### 7. Final predictions\n",
    "The test set will not be used and looked at until the end. The test set will only be used on the final model and to draw final conclusions about the pros and cons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The communication\n",
    "\n",
    "Here you can discuss your plan for analysis and communication of your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of a Power Point slide deck or Jupyter Notebook that goes thorugh the findings of each of the seven steps from the pipeline. In the final communication I only intend to use summaries for each of the seven steps.\n",
    "\n",
    "I deem this project to be interesting as their does not seem to be a lot of data cleasing to be necessary. Hence, I might be able to focus strongly on feature engineering, model building, evaluation and tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
